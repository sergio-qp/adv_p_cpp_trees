# You must program this function, first in R, then in C++
gini_impurity_R <- function(left,right){
# first, we calculate left and right gini scores using the formula provided, getting the ratio of 1s and 0s in each
ginileft = 1 - ( (sum(left)/length(left))^2 + (( 1-(sum(left)/length(left)) )^2) )
giniright = 1 - ( (sum(right)/length(right))^2 + (( 1-(sum(right)/length(right)) )^2) )
tot_length = length(left) + length(right) #length of the collective data
# calculate weighted average gini using formula and return it
avg_gini = (length(left)/tot_length)*ginileft + (length(right)/tot_length)*giniright
avg_gini
}
best_split_R <- function(X, y) {
best_gini <- 1.0
best_feature <- -1
n_features <- ncol(X)
for (feature in 1:n_features) {
values <- unique(X[, feature])
for (value in values) {
left_indices <- X[, feature] == value
right_indices <- X[, feature] != value
left <- y[left_indices]
right <- y[right_indices]
gini <- gini_impurity_R(left, right)
if (gini < best_gini) {
best_gini <- gini
best_feature <- feature # Store the best feature index
best_value <- value
}
}
}
output <- list(
best_feature = best_feature,
best_value = best_value,
best_gini = best_gini
)
output
}
fit_decision_stump_R <- function(X, y) {
best_split_R(X, y) # Call best_split and return the best feature index
}
source("R\\utils.R") #call our utils script
setwd("C:/Users/sergi/Desktop/Carlos III/Advanced Programming/Decision trees project/myds/R")
source("utils.R") #call our utils script
#REPORT WHAT HAPPENS WHEN YOU CHANGE MAXDEPTH
model <- rpart(PlayTennis ~ ., tennis_data,
control = rpart.control(cp = 0, maxdepth = 5, minsplit = 1,
minbucket = 1))
#REPORT WHAT HAPPENS WHEN YOU CHANGE MAXDEPTH
model <- rpart(PlayTennis ~ ., play_tennis,
control = rpart.control(cp = 0, maxdepth = 5, minsplit = 1,
minbucket = 1))
# You must program this function, first in R, then in C++
gini_impurity_R <- function(left,right){
# first, we calculate left and right gini scores using the formula provided, getting the ratio of 1s and 0s in each
ginileft = 1 - ( (sum(left)/length(left))^2 + (( 1-(sum(left)/length(left)) )^2) )
giniright = 1 - ( (sum(right)/length(right))^2 + (( 1-(sum(right)/length(right)) )^2) )
tot_length = length(left) + length(right) #length of the collective data
# calculate weighted average gini using formula and return it
avg_gini = (length(left)/tot_length)*ginileft + (length(right)/tot_length)*giniright
avg_gini
}
best_split_R <- function(X, y) {
best_gini <- 1.0
best_feature <- -1
n_features <- ncol(X)
for (feature in 1:n_features) {
values <- unique(X[, feature])
for (value in values) {
left_indices <- X[, feature] == value
right_indices <- X[, feature] != value
left <- y[left_indices]
right <- y[right_indices]
gini <- gini_impurity_R(left, right)
if (gini < best_gini) {
best_gini <- gini
best_feature <- feature # Store the best feature index
best_value <- value
best_left = left
best_right = right
}
}
}
output <- list(
best_feature = best_feature,
best_value = best_value,
best_gini = best_gini,
best_left = best_left,
best_right = best_right
)
output
}
fit_decision_stump_R <- function(X, y) {
best_split_R(X, y) # Call best_split and return the best feature index
}
source("R/utils.R") #call our utils script
#X is factor matrix, y is response matrix, we apply the num_matrix function right away cuz why not
X = num_matrix_from_df(play_tennis[c(-5)])
y = num_matrix_from_df(play_tennis[c(5)])
fit_decision_stump_R(X,y) #nice, it seems to work
library(Rcpp)
sourceCpp('src\\ds_cpp.cpp')
best_split_R(X, y)
best_split_C(X, y)
best_left= c(1, 1, 1, 1)
best_right = c(0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0)
gini_impurity_C(best_left,best_right)
gini_impurity_R(best_left,best_right)
sourceCpp('src\\ds_cpp.cpp')
best_split_C(X, y)
sourceCpp('src\\ds_cpp.cpp')
best_split_C(X, y)
best_split_R(X, y)
sourceCpp('src\\ds_cpp.cpp')
best_split_C(X, y)
sourceCpp('src\\ds_cpp.cpp')
best_split_C(X, y)
sourceCpp('src\\ds_cpp.cpp')
best_split_C(X, y)
sourceCpp('src\\ds_cpp.cpp')
best_split_C(X, y)
install.packages("microbenchmark")
library(microbenchmark)
microbenchmark(
best_split_R(vec),
best_split_C(vec),
times = 10  # Run each function 100 times
)
microbenchmark(
best_split_R(X, y),
best_split_C(X, y),
times = 10  # Run each function 100 times
)
microbenchmark(
best_split_R(X, y),
best_split_C(X, y),
times = 100  # Run each function 100 times
)
microbenchmark(
best_split_R(X, y),
best_split_C(X, y),
times = 100
)
fit_decision_stump_R <- function(X, y) {
best_split_R(X, y) # Call best_split and return the best feature index
}
fit_decision_stump_R(X,y) #nice, it seems to work
rand_y = sample(y)
rand_y
y
rand_y
best_split_R(X, rand_y)
best_split_C(X, rand_y)
X
best_split_R <- function(X, y) {
best_gini <- 1.0
best_feature <- -1
n_features <- ncol(X)
for (feature in 1:n_features) {
values <- unique(X[, feature])
for (value in sort(values)) {
left_indices <- X[, feature] == value
right_indices <- X[, feature] != value
left <- y[left_indices]
right <- y[right_indices]
gini <- gini_impurity_R(left, right)
if (gini < best_gini) {
best_gini <- gini
best_feature <- feature # Store the best feature index
best_value <- value
best_left = left
best_right = right
}
}
}
output <- list(
best_feature = best_feature,
best_value = best_value,
best_gini = best_gini,
best_left = best_left,
best_right = best_right
)
output
}
best_split_R(X, rand_y)
best_split_C(X, rand_y)
sum(best_left[best_left == 0])
sum(best_left[best_left == 1])
best_split_R <- function(X, y) {
best_gini <- 1.0
best_feature <- -1
n_features <- ncol(X)
for (feature in 1:n_features) {
values <- unique(X[, feature])
for (value in sort(values)) { #important to include sort or it doesn't match with the C version
left_indices <- X[, feature] == value
right_indices <- X[, feature] != value
left <- y[left_indices]
right <- y[right_indices]
gini <- gini_impurity_R(left, right)
if (sum(left[left == 0]) > sum(left[left == 1])) { left_majority = "No"; right_majority = "Yes"; }
else { left_majority = "Yes"; right_majority = "No"; }
if (gini < best_gini) {
best_gini <- gini
best_feature <- feature # Store the best feature index
best_value <- value
left_majority = left_majority
right_majority = right_majority
}
}
}
output <- list(
best_feature = best_feature,
best_value = best_value,
best_gini = best_gini,
left_majority = left_majority,
right_majority = right_majority
)
output
}
best_split_R(X, rand_y)
best_split_R(X, y)
sourceCpp('src\\ds_cpp.cpp')
sourceCpp('src\\ds_cpp.cpp')
best_split_C(X, y)
best_split_R(X, y)
best_split_C(X, y)
sourceCpp('src\\ds_cpp.cpp')
best_split_R(X, y)
best_split_C(X, y)
#microbenchmarking, looks good
microbenchmark(
best_split_R(X, y),
best_split_C(X, y),
times = 1000
)
install.packages('myds_1.0.tar', repos = NULL, type="source")
install.packages('myds_1.0.tar.gz', repos = NULL, type="source")
setwd("C:/Users/sergi/Desktop/Carlos III/Advanced Programming/testfolder")
install.packages('myds_1.0.tar.gz', repos = NULL, type="source")
library(myds_1.0)
library(myds)
install.packages('myds_1.0.tar.gz', repos = NULL, type="source")
install.packages('myds_1.0.tar.gz', repos = NULL, type="source")
library(myds)
X
y
best_split_R(X, y)
best_split_C(X, y)
microbenchmark(
best_split_R(X, y),
best_split_C(X, y),
times = 100
)
